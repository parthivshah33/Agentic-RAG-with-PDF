{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "Implimenting RAG Pipeline with Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    task_type=\"retrieval_document\",\n",
    "    google_api_key=\"AIzaSyD1z3cmhCJfg-LqIUn92CarN91eCkUXrCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_a3dKK_6ReQWZL9CrXVcvMBmq6JXNtAPvZjTAWs1nrcR53UBvG8AdfcjT8q38Ued7k62z6\")\n",
    "index = pc.Index(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embedding_client)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdoc = retriever.invoke(\"what is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"Document Retriever Tool\",\n",
    "    description=\"Tool to fetch documents from a database whenever a query is given.\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Nodes and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Prompt[parthiv/rag-prompt-llama]********************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatGroq(temperature=0.1,\n",
    "                     model_name=\"llama-3.3-70b-versatile\",\n",
    "                     api_key=\"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\")\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatGroq(temperature=0.5,\n",
    "                     model_name=\"llama-3.3-70b-versatile\",\n",
    "                     api_key=\"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\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"parthiv/rag-prompt-llama\")\n",
    "\n",
    "    llm = ChatGroq(temperature=0,\n",
    "                   model_name=\"llama-3.3-70b-versatile\",\n",
    "                   api_key=\"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\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "print(\"*\" * 20 + \"Prompt[parthiv/rag-prompt-llama]\" + \"*\" * 20)\n",
    "# Show what the prompt looks like\n",
    "prompt = hub.pull(\n",
    "    \"parthiv/rag-prompt-llama\").pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges\n",
    "def grade_documents(state) -> Literal[\"generate\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatGroq(temperature=0.1,\n",
    "                     model_name=\"llama-3.3-70b-versatile\",\n",
    "                     api_key=\"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\")\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "    return \"generate\"  # forcefuly return 'generate' for we removed 'rewrite' from the graph due to some issues in prompt\n",
    "    # if score == \"yes\":\n",
    "    #     print(\"---DECISION: DOCS RELEVANT---\")\n",
    "    #     return \"generate\"\n",
    "\n",
    "    # else:\n",
    "    #     print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "    #     print(score)\n",
    "    #     return \"rewrite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "# workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    "\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "# workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m      3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      5\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is Required for Achieving More Using Deep Learning? \u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     ]\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream(inputs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     10\u001b[0m         pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput from node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1660\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1661\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1662\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1663\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1664\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1665\u001b[0m         ):\n\u001b[0;32m   1666\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[20], line 18\u001b[0m, in \u001b[0;36magent\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatGroq(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     15\u001b[0m                  model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.3-70b-versatile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m                  api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgsk_yDps87ftjwCFq5rL26H5WGdyb3FY6vcl3BUGE1ETJf8MDXWzQtyp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbind_tools(tools)\n\u001b[1;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# We return a list, because this will get added to the existing list\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5353\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5356\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\langchain_groq\\chat_models.py:480\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    476\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    479\u001b[0m }\n\u001b[1;32m--> 480\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\groq\\resources\\chat\\completions.py:298\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\groq\\_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1251\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1260\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1261\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1262\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\groq\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PARTHIV\\anaconda3\\envs\\chatbotenv\\lib\\site-packages\\groq\\_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1067\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"What is Required for Achieving More Using Deep Learning? \"),\n",
    "    ]\n",
    "}\n",
    "for output in graph.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve more using deep learning, supercomputing power is a mandatory requirement. This includes having both memory and a strong CPU to develop deep learning models. Fortunately, the easy availability of High Performance Computing (HPC) has made it more accessible to develop these models.\n"
     ]
    }
   ],
   "source": [
    "print(value['messages'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
